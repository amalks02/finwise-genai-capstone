{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMWmZrajYwI1QFta3Ih5v6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalks02/finwise-genai-capstone/blob/chat-bot/chat_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2GKSOztdLm1"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U langchain-google-genai gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required packages\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "E1PlaXPUdQV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Gemini API\n",
        "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "8OkbSQ9PdhcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)"
      ],
      "metadata": {
        "id": "a3RaxSX2dkvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Langchain memory\n",
        "memory = ConversationBufferMemory(return_messages=True)"
      ],
      "metadata": {
        "id": "Aem5HlmTd0Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customer data\n",
        "customer_data = {\n",
        "    \"name\": \"Amit Sharma\",\n",
        "    \"balance\": 125000,\n",
        "    \"credit_card_due\": 20000\n",
        "}"
      ],
      "metadata": {
        "id": "Ty0YJrFueBvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading customer profile into memory\n",
        "memory.save_context(\n",
        "    {\"input\": \"System preload\"},\n",
        "    {\"output\": f\"Customer profile: {customer_data}\"}\n",
        ")"
      ],
      "metadata": {
        "id": "Xzrp7oG2eH5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build conversational chain\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "pYAga_mTeKJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to process the user input\n",
        "def process_user_input(user_input: str):\n",
        "    global customer_data\n",
        "    text = user_input.lower()\n",
        "\n",
        "    # Balance inquiry\n",
        "    if \"balance\" in text:\n",
        "        return f\"Your current balance is ₹{customer_data['balance']:,}.\"\n",
        "\n",
        "    # Transfer money\n",
        "    elif \"transfer\" in text:\n",
        "        words = text.split()\n",
        "        amount = None\n",
        "        for word in words:\n",
        "            if word.isdigit():\n",
        "                amount = int(word)\n",
        "                break\n",
        "\n",
        "        if amount is None:\n",
        "            return \"Please tell me how much you want to transfer.\"\n",
        "\n",
        "        if amount > customer_data[\"balance\"]:\n",
        "            return \"Insufficient funds for this transfer.\"\n",
        "\n",
        "        # Update balances\n",
        "        customer_data[\"balance\"] -= amount\n",
        "        customer_data[\"credit_card_due\"] = max(\n",
        "            0, customer_data[\"credit_card_due\"] - amount\n",
        "        )\n",
        "\n",
        "        return (f\"₹{amount:,} transferred to your credit card. \"\n",
        "                f\"New balance: ₹{customer_data['balance']:,}. \"\n",
        "                f\"Remaining credit card due: ₹{customer_data['credit_card_due']:,}.\")\n",
        "\n",
        "    # Fallback to LLM\n",
        "    else:\n",
        "        return conversation.predict(input=user_input)\n"
      ],
      "metadata": {
        "id": "ifoxmafFeNyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Banking Chatbot with Memory\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=400)\n",
        "    msg = gr.Textbox(placeholder=\"Ask me about your account...\")\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    def respond(user_input, chat_history):\n",
        "        response = process_user_input(user_input)\n",
        "        chat_history.append((user_input, response))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "id": "_R-_VnWjeir7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
