{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1D98GwlUtXj0kCrmunP5y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalks02/finwise-genai-capstone/blob/task-02-agent-tools-langgraph/agent_with_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSboXH4aeQ7J"
      },
      "outputs": [],
      "source": [
        "# agent_with_tools.ipynb\n",
        "\n",
        "import os\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import BaseMessage, ToolMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# Import tools\n",
        "from tools_config import calculator, python_repl, requests_tool\n",
        "\n",
        "# --------------------\n",
        "# Tool list and lookup\n",
        "# --------------------\n",
        "tools = [calculator, python_repl, requests_tool]\n",
        "tools_by_name = {t.name: t for t in tools}\n",
        "\n",
        "# --------------------\n",
        "# Define Agent State\n",
        "# --------------------\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "# --------------------\n",
        "# Initialize Gemini LLM\n",
        "# --------------------\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    temperature=0,\n",
        "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
        ")\n",
        "\n",
        "# Bind tools to LLM\n",
        "model = llm.bind_tools(tools)\n",
        "\n",
        "# --------------------\n",
        "# Graph Nodes\n",
        "# --------------------\n",
        "def call_model(state: AgentState):\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def call_tool(state: AgentState):\n",
        "    outputs = []\n",
        "    last = state[\"messages\"][-1]\n",
        "    for tool_call in getattr(last, \"tool_calls\", []):\n",
        "        name = tool_call[\"name\"]\n",
        "        args = tool_call[\"args\"]\n",
        "        tool = tools_by_name.get(name)\n",
        "        if tool:\n",
        "            result = tool.invoke(args)\n",
        "        else:\n",
        "            result = {\"error\": f\"Tool {name} not found\"}\n",
        "        outputs.append(ToolMessage(content=result, name=name, tool_call_id=tool_call[\"id\"]))\n",
        "    return {\"messages\": outputs}\n",
        "\n",
        "def should_continue(state: AgentState):\n",
        "    messages = state[\"messages\"]\n",
        "    if not getattr(messages[-1], \"tool_calls\", None):\n",
        "        return \"end\"\n",
        "    return \"continue\"\n",
        "\n",
        "# --------------------\n",
        "# Build workflow\n",
        "# --------------------\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"llm\", call_model)\n",
        "workflow.add_node(\"tools\", call_tool)\n",
        "workflow.set_entry_point(\"llm\")\n",
        "workflow.add_conditional_edges(\"llm\", should_continue, {\"continue\": \"tools\", \"end\": END})\n",
        "workflow.add_edge(\"tools\", \"llm\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "# --------------------\n",
        "# Example Queries\n",
        "# --------------------\n",
        "\n",
        "# EMI calculation\n",
        "inputs_emi = {\"messages\": [(\"user\", \"What’s the EMI for a ₹10L loan over 5 years at 8.5% interest?\")]}\n",
        "for state in graph.stream(inputs_emi, stream_mode=\"values\"):\n",
        "    state[\"messages\"][-1].pretty_print()\n",
        "\n",
        "# Currency conversion\n",
        "inputs_currency = {\"messages\": [(\"user\", \"Convert 5000 INR to USD using a live API.\")]}\n",
        "for state in graph.stream(inputs_currency, stream_mode=\"values\"):\n",
        "    state[\"messages\"][-1].pretty_print()\n",
        "\n",
        "# --------------------\n",
        "# Interactive user input\n",
        "# --------------------\n",
        "query = input(\"Ask your question: \")\n",
        "inputs_user = {\"messages\": [(\"user\", query)]}\n",
        "for state in graph.stream(inputs_user, stream_mode=\"values\"):\n",
        "    state[\"messages\"][-1].pretty_print()\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "print(os.getenv(\"GEMINI_API_KEY\"))"
      ]
    }
  ]
}